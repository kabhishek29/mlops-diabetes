{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/democompute/code/Users/callkabhishek/diabetes'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1660185237438
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\r\n",
        "import azureml.core\r\n",
        "import os,json,sys\r\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "\r\n",
        "print('SDK Version:', azureml.core.VERSION)\r\n",
        "\r\n",
        "with open(\"./aml_config/config.json\") as f:\r\n",
        "    config=json.load(f)\r\n",
        "\r\n",
        "workspace_name=config[\"workspace_name\"]\r\n",
        "print(workspace_name)\r\n",
        "\r\n",
        "resource_group=config[\"resource_group\"]\r\n",
        "subscription_id=config[\"subscription_id\"]\r\n",
        "\r\n",
        "inter_auth=InteractiveLoginAuthentication()\r\n",
        "#ws = Workspace.from_config()\r\n",
        "\r\n",
        "ws = Workspace.get(name=workspace_name, subscription_id=subscription_id,resource_group=resource_group,auth=inter_auth) \r\n",
        "print(ws.name, ws.resource_group,ws.subscription_id)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK Version: 1.42.0\nmlops-demo\nmlops-demo rg-mlops-demo 2279dc50-0d1e-45f3-8ba1-6832bc4b5b02\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298073256
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "experiment = Experiment(workspace=ws, name=\"diabetes-experiment\")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298148860
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.opendatasets import Diabetes\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_df = Diabetes.get_tabular_dataset().to_pandas_dataframe().dropna()\r\n",
        "y_df = x_df.pop(\"Y\")\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=66)\r\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298188692
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.externals import joblib\r\n",
        "import math\r\n",
        "\r\n",
        "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\r\n",
        "\r\n",
        "for alpha in alphas:\r\n",
        "    run = experiment.start_logging()\r\n",
        "    run.log(\"alpha_value\", alpha)\r\n",
        "    \r\n",
        "    model = Ridge(alpha=alpha)\r\n",
        "    model.fit(X=X_train, y=y_train)\r\n",
        "    y_pred = model.predict(X=X_test)\r\n",
        "    rmse = math.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred))\r\n",
        "    run.log(\"rmse\", rmse)\r\n",
        "    \r\n",
        "    model_name = \"model_alpha_\" + str(alpha) + \".pkl\"\r\n",
        "    filename = \"outputs/\" + model_name\r\n",
        "    \r\n",
        "    joblib.dump(value=model, filename=filename)\r\n",
        "    run.upload_file(name=model_name, path_or_stream=filename)\r\n",
        "    run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n  warnings.warn(msg, category=FutureWarning)\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298257138
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "Experiment(Name: diabetes-experiment,\nWorkspace: mlops-demo)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>diabetes-experiment</td><td>mlops-demo</td><td><a href=\"https://ml.azure.com/experiments/id/17f2cb29-57e1-4d76-af7b-1904e5bb4c4c?wsid=/subscriptions/2279dc50-0d1e-45f3-8ba1-6832bc4b5b02/resourcegroups/rg-mlops-demo/workspaces/mlops-demo&amp;tid=4c0eaf3d-f27d-4e25-9247-16edb5fb6a7d\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298268853
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minimum_rmse_runid = None\r\n",
        "minimum_rmse = None\r\n",
        "\r\n",
        "for run in experiment.get_runs():\r\n",
        "    run_metrics = run.get_metrics()\r\n",
        "    run_details = run.get_details()\r\n",
        "    # each logged metric becomes a key in this returned dict\r\n",
        "    run_rmse = run_metrics[\"rmse\"]\r\n",
        "    run_id = run_details[\"runId\"]\r\n",
        "    \r\n",
        "    if minimum_rmse is None:\r\n",
        "        minimum_rmse = run_rmse\r\n",
        "        minimum_rmse_runid = run_id\r\n",
        "    else:\r\n",
        "        if run_rmse < minimum_rmse:\r\n",
        "            minimum_rmse = run_rmse\r\n",
        "            minimum_rmse_runid = run_id\r\n",
        "\r\n",
        "print(\"Best run_id: \" + minimum_rmse_runid)\r\n",
        "print(\"Best run_id rmse: \" + str(minimum_rmse))    \r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best run_id: de0c3bf9-5adb-42f3-aa06-f7a9d4ce8481\nBest run_id rmse: 56.605203313391435\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298279046
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Run\r\n",
        "best_run = Run(experiment=experiment, run_id=minimum_rmse_runid)\r\n",
        "print(best_run.get_file_names())\r\n",
        "\r\n",
        "\r\n",
        "# Call `download()` on the run object, specifying the model file name to download. By default this function downloads to the current directory.\r\n",
        "\r\n",
        "# In[9]:\r\n",
        "\r\n",
        "best_run.download_file(name=\"model_alpha_0.1.pkl\")\r\n",
        "print(\"Best performing experiment run identified\")\r\n",
        "\r\n",
        "print(\"Registering best run model with the Azureml workspace\")\r\n",
        "model = best_run.register_model(model_name='diabetes-model', \r\n",
        "                                model_path='model_alpha_0.1.pkl')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['model_alpha_0.1.pkl', 'outputs/.amlignore', 'outputs/.amlignore.amltmp', 'outputs/model_alpha_0.1.pkl', 'outputs/model_alpha_0.2.pkl', 'outputs/model_alpha_0.3.pkl', 'outputs/model_alpha_0.4.pkl', 'outputs/model_alpha_0.5.pkl', 'outputs/model_alpha_0.6.pkl', 'outputs/model_alpha_0.7.pkl', 'outputs/model_alpha_0.8.pkl', 'outputs/model_alpha_0.9.pkl', 'outputs/model_alpha_1.0.pkl']\nBest performing experiment run identified\nRegistering best run model with the Azureml workspace\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298324300
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_model_path\r\n",
        "#model.name"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<function azureml.core.model.Model.get_model_path(model_name, version=None, _workspace=None)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298332786
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Creating deploy environment yaml file\")\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies \r\n",
        "from azureml.core.image import ContainerImage\r\n",
        "\r\n",
        "# Create an empty conda environment and add the scikit-learn package\r\n",
        "env = CondaDependencies()\r\n",
        "env.add_conda_package(\"scikit-learn\")\r\n",
        "\r\n",
        "# Display the environment\r\n",
        "print(env.serialize_to_string())\r\n",
        "\r\n",
        "# Write the environment to disk\r\n",
        "with open(\"myenv.yml\",\"w\") as f:\r\n",
        "    f.write(env.serialize_to_string())\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Creating deploy environment yaml file\n# Conda environment specification. The dependencies defined in this file will\r\n# be automatically provisioned for runs with userManagedDependencies=False.\r\n\n# Details about the Conda environment file format:\r\n# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n\nname: project_environment\ndependencies:\n  # The python interpreter version.\r\n  # Currently Azure ML only supports 3.5.2 and later.\r\n- python=3.8.12\n\n- pip:\n    # Required packages for AzureML execution, history, and data preparation.\r\n  - azureml-defaults\n\n- scikit-learn\nchannels:\n- anaconda\n- conda-forge\n\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298338548
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AksCompute, ComputeTarget\r\n",
        "\r\n",
        "# Use the default configuration (you can also provide parameters to customize this)\r\n",
        "#prov_config = AksCompute.provisioning_configuration(location=\"westeurope\",vm_size=\"Standard_DS3_V2\")\r\n",
        "prov_config = AksCompute.provisioning_configuration(vm_size=\"Standard_DS2_V2\")\r\n",
        "\r\n",
        "aks_cluster_name = \"mlopscluster\"\r\n",
        "# Create the cluster\r\n",
        "aks_target = ComputeTarget.create(workspace = ws, \r\n",
        "                                  name = aks_cluster_name, \r\n",
        "                                  provisioning_configuration = prov_config)\r\n",
        "\r\n",
        "# Wait for the create process to complete\r\n",
        "aks_target.wait_for_completion(show_output = True)\r\n",
        "print(aks_target.provisioning_state)\r\n",
        "print(aks_target.provisioning_errors)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress..................................................................\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nNone\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660187317073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AksCompute\r\n",
        "from azureml.exceptions import ComputeTargetException\r\n",
        "\r\n",
        "# Choose a name for your cluster\r\n",
        "aks_cluster_name = \"mlopscluster\"\r\n",
        "\r\n",
        "# Check to see if the cluster already exists\r\n",
        "try:\r\n",
        "    aks_target = ComputeTarget(workspace=ws, name=aks_cluster_name)\r\n",
        "    print('Found existing compute target')\r\n",
        "except ComputeTargetException:\r\n",
        "    print('Creating a new compute target...')\r\n",
        "\r\n",
        "    aks_target = ComputeTarget.create(workspace = ws, \r\n",
        "                                  name = aks_cluster_name, \r\n",
        "                                  provisioning_configuration = prov_config)\r\n",
        "\r\n",
        "\r\n",
        "    aks_target.wait_for_completion(show_output=True)\r\n",
        "    print(aks_target.provisioning_state)\r\n",
        "    print(aks_target.provisioning_errors)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute target\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298349421
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "inference_config = InferenceConfig(runtime= \"python\",\r\n",
        "                                              #source_directory=\"script_folder\",\r\n",
        "                                              entry_script=\"score.py\",\r\n",
        "                                              conda_file=\"myenv.yml\")\r\n"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298353058
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aks_target = AksCompute(ws,\"mlopscluster\")\r\n",
        "service_name=\"diabetes-svc-v1\"\r\n"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298356487
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AksWebservice, Webservice\r\n",
        "from azureml.core.compute import AksCompute\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "\r\n",
        "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 0.5, memory_gb = 2)\r\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, aks_target)\r\n",
        "\r\n",
        "service.wait_for_deployment(show_output = True)\r\n",
        "print(service.state)\r\n",
        "print(service.get_logs())\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading model diabetes-model:6 to /tmp/azureml_t001txwf/diabetes-model/6\nGenerating Docker build context.\nPackage creation Succeeded\nLogging into Docker registry acrmlopsdemo1.azurecr.io\nLogging into Docker registry acrmlopsdemo1.azurecr.io\nBuilding Docker image from Dockerfile...\nStep 1/5 : FROM acrmlopsdemo1.azurecr.io/azureml/azureml_a4ef8c288de4e4de116146287923748e\n ---> cee3f1012804\nStep 2/5 : COPY azureml-app /var/azureml-app\n ---> a8d6cf37b20e\nStep 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjIyNzlkYzUwLTBkMWUtNDVmMy04YmExLTY4MzJiYzRiNWIwMiIsInJlc291cmNlR3JvdXBOYW1lIjoicmctbWxvcHMtZGVtbyIsImFjY291bnROYW1lIjoibWxvcHMtZGVtbyIsIndvcmtzcGFjZUlkIjoiNTY0NWMyZGYtOTBhOS00MDQ5LWI2MGItOTFmYTUzNWJhNzhhIn0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n ---> Running in 5fb3ecfe4a63\n ---> 6e343e9a1da6\nStep 4/5 : RUN mv '/var/azureml-app/tmp3gv2c2r7.py' /var/azureml-app/main.py\n ---> Running in 03a9f8da8e41\n ---> 9d29a76f8079\nStep 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n ---> Running in 8a9ef977d084\n ---> 423fa2853887\nSuccessfully built 423fa2853887\nSuccessfully tagged test:latest\nContainer (name:distracted_franklin, id:da72aa2f12af9c03cadc2b77cada9cb1d3b30c4b3a6115b9c36e8664d4e8c7ea) cannot be killed.\nContainer has been successfully cleaned up.\nImage sha256:1f1b75766bf977b29d1908bccb36c93a0aa881c3354f489f3f76900d2ccc55ab successfully removed.\nStarting Docker container...\nDocker container running.\nChecking container health...\n"
        }
      ],
      "execution_count": 85,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660202286605
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_service.get_logs()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "'/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n2022-08-11T03:27:27,221107835+00:00 - gunicorn/run \\n2022-08-11T03:27:27,222992266+00:00 | gunicorn/run | \\n2022-08-11T03:27:27,227171457+00:00 - iot-server/run \\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n2022-08-11T03:27:27,231338247+00:00 - rsyslog/run \\nbash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by bash)\\n2022-08-11T03:27:27,234480465+00:00 | gunicorn/run | ###############################################\\n2022-08-11T03:27:27,242833146+00:00 | gunicorn/run | AzureML Container Runtime Information\\n2022-08-11T03:27:27,246169878+00:00 - nginx/run \\n2022-08-11T03:27:27,256261779+00:00 | gunicorn/run | ###############################################\\n2022-08-11T03:27:27,258331523+00:00 | gunicorn/run | \\n2022-08-11T03:27:27,262356903+00:00 | gunicorn/run | \\n2022-08-11T03:27:27,263924812+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\n2022-08-11T03:27:27,265522623+00:00 | gunicorn/run | PYTHONPATH environment variable: \\n2022-08-11T03:27:27,269168477+00:00 | gunicorn/run | \\n2022-08-11T03:27:27,278713240+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\\n\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n2022-08-11T03:27:27,314959660+00:00 - iot-server/finish 1 0\\n2022-08-11T03:27:27,316419662+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nadal==1.2.7\\nargcomplete==2.0.0\\nattrs==22.1.0\\nazure-common==1.1.28\\nazure-core==1.25.0\\nazure-graphrbac==0.61.1\\nazure-identity==1.7.0\\nazure-mgmt-authorization==2.0.0\\nazure-mgmt-containerregistry==10.0.0\\nazure-mgmt-core==1.3.1\\nazure-mgmt-keyvault==10.1.0\\nazure-mgmt-resource==21.1.0\\nazure-mgmt-storage==20.0.0\\nazureml-core==1.44.0\\nazureml-dataprep==4.2.2\\nazureml-dataprep-native==38.0.0\\nazureml-dataprep-rslex==2.8.1\\nazureml-dataset-runtime==1.44.0\\nazureml-defaults==1.44.0\\nazureml-inference-server-http==0.7.4\\nbackports.tempfile==1.0\\nbackports.weakref==1.0.post1\\nbcrypt==3.2.2\\ncachetools==5.2.0\\ncertifi @ file:///opt/conda/conda-bld/certifi_1655968806487/work/certifi\\ncffi==1.15.1\\ncharset-normalizer==2.1.0\\nclick==8.1.3\\ncloudpickle==2.1.0\\nconfigparser==3.7.4\\ncontextlib2==21.6.0\\ncryptography==37.0.4\\ndistro==1.7.0\\ndocker==5.0.3\\ndotnetcore2==3.1.23\\nFlask==2.1.3\\nFlask-Cors==3.0.10\\nfusepy==3.0.1\\ngoogle-api-core==2.8.2\\ngoogle-auth==2.10.0\\ngoogleapis-common-protos==1.56.4\\ngunicorn==20.1.0\\nhumanfriendly==10.0\\nidna==3.3\\nimportlib-metadata==4.12.0\\nimportlib-resources==5.9.0\\ninference-schema==1.4.1\\nisodate==0.6.1\\nitsdangerous==2.1.2\\njeepney==0.8.0\\nJinja2==3.1.2\\njmespath==1.0.0\\njoblib @ file:///tmp/build/80754af9/joblib_1635411271373/work\\njson-logging-py==0.2\\njsonpickle==2.2.0\\njsonschema==4.9.1\\nknack==0.9.0\\nMarkupSafe==2.1.1\\nmkl-fft==1.3.1\\nmkl-random @ file:///tmp/build/80754af9/mkl_random_1626186064646/work\\nmkl-service==2.4.0\\nmsal==1.18.0\\nmsal-extensions==0.3.1\\nmsrest==0.7.1\\nmsrestazure==0.6.4\\nndg-httpsclient==0.5.1\\nnumpy @ file:///opt/conda/conda-bld/numpy_and_numpy_base_1652801679809/work\\noauthlib==3.2.0\\nopencensus==0.11.0\\nopencensus-context==0.1.3\\nopencensus-ext-azure==1.1.6\\npackaging==21.3\\nparamiko==2.11.0\\npathspec==0.9.0\\npkginfo==1.8.3\\npkgutil_resolve_name==1.3.10\\nportalocker==2.5.1\\nprotobuf==4.21.5\\npsutil==5.9.1\\npyarrow==6.0.0\\npyasn1==0.4.8\\npyasn1-modules==0.2.8\\npycparser==2.21\\nPygments==2.12.0\\nPyJWT==2.4.0\\nPyNaCl==1.5.0\\npyOpenSSL==22.0.0\\npyparsing==3.0.9\\npyrsistent==0.18.1\\nPySocks==1.7.1\\npython-dateutil==2.8.2\\npytz==2022.1\\nPyYAML==6.0\\nrequests==2.28.1\\nrequests-oauthlib==1.3.1\\nrsa==4.9\\nscikit-learn @ file:///tmp/build/80754af9/scikit-learn_1642617107864/work\\nscipy @ file:///tmp/build/80754af9/scipy_1641555001653/work\\nSecretStorage==3.3.2\\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\\ntabulate==0.8.10\\nthreadpoolctl @ file:///Users/ktietz/demo/mc3/conda-bld/threadpoolctl_1629802263681/work\\ntyping_extensions==4.3.0\\nurllib3==1.26.9\\nwebsocket-client==1.3.3\\nWerkzeug==2.2.2\\nwrapt==1.12.1\\nzipp==3.8.1\\n\\n2022-08-11T03:27:27,772321256+00:00 | gunicorn/run | \\n2022-08-11T03:27:27,774122982+00:00 | gunicorn/run | ###############################################\\n2022-08-11T03:27:27,779927985+00:00 | gunicorn/run | AzureML Inference Server\\n2022-08-11T03:27:27,783391726+00:00 | gunicorn/run | ###############################################\\n2022-08-11T03:27:27,785008639+00:00 | gunicorn/run | \\n2022-08-11T03:27:27,786954474+00:00 | gunicorn/run | \\n2022-08-11T03:27:27,788513782+00:00 | gunicorn/run | Starting HTTP server\\n2022-08-11T03:27:27,790123894+00:00 | gunicorn/run | \\nStarting gunicorn 20.1.0\\nListening at: http://127.0.0.1:31311 (10)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 55\\nSPARK_HOME not set. Skipping PySpark Initialization.\\nEncountered exception while trying to load score script: Traceback (most recent call last):\\n  File \"/var/azureml-server/aml_blueprint.py\", line 36, in <module>\\n    import main\\n  File \"/var/azureml-app/main.py\", line 12, in <module>\\n    driver_module_spec.loader.exec_module(driver_module)\\n  File \"/structure/azureml-app/score.py\", line 5, in <module>\\n    from sklearn.externals import joblib\\nImportError: cannot import name \\'joblib\\' from \\'sklearn.externals\\' (/azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/python3.8/site-packages/sklearn/externals/__init__.py)\\n\\nWorker exiting (pid: 55)\\nShutting down: Master\\nReason: Worker failed to boot.\\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n2022-08-11T03:27:28,718082107+00:00 - gunicorn/finish 3 0\\n2022-08-11T03:27:28,719552509+00:00 - Exit code 3 is not normal. Killing image.\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660188492728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\r\n",
        "from azureml.core.webservice import LocalWebservice\r\n",
        "\r\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=6789)\r\n",
        "\r\n",
        "local_service = Model.deploy(ws, \"test\", [model], inference_config, deployment_config)\r\n",
        "\r\n",
        "local_service.wait_for_deployment()\r\n",
        "print(local_service.state)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading model diabetes-model:7 to /tmp/azureml_h0pwrkrg/diabetes-model/7\nGenerating Docker build context.\nPackage creation Succeeded\nLogging into Docker registry acrmlopsdemo1.azurecr.io\nLogging into Docker registry acrmlopsdemo1.azurecr.io\nBuilding Docker image from Dockerfile...\nStep 1/5 : FROM acrmlopsdemo1.azurecr.io/azureml/azureml_a4ef8c288de4e4de116146287923748e\n ---> cee3f1012804\nStep 2/5 : COPY azureml-app /var/azureml-app\n ---> b4f30deabf06\nStep 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjIyNzlkYzUwLTBkMWUtNDVmMy04YmExLTY4MzJiYzRiNWIwMiIsInJlc291cmNlR3JvdXBOYW1lIjoicmctbWxvcHMtZGVtbyIsImFjY291bnROYW1lIjoibWxvcHMtZGVtbyIsIndvcmtzcGFjZUlkIjoiNTY0NWMyZGYtOTBhOS00MDQ5LWI2MGItOTFmYTUzNWJhNzhhIn0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n ---> Running in f47aa7d616f7\n ---> f69e6218ab7b\nStep 4/5 : RUN mv '/var/azureml-app/tmpjomp39pr.py' /var/azureml-app/main.py\n ---> Running in 241492b7f343\n ---> 525e1af43d5c\nStep 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n ---> Running in 97d55c7462f1\n ---> a9ee6928deb9\nSuccessfully built a9ee6928deb9\nSuccessfully tagged test:latest\nContainer (name:gallant_haslett, id:ff78b644782fefbf3d3b88df199360d847e27eff7b62aa035576dd75f53736ad) cannot be killed.\nContainer has been successfully cleaned up.\nImage sha256:423fa28538873a73b80edd3f076cfc69531bffdee94a6b51867820db300213bb successfully removed.\nStarting Docker container...\nDocker container running.\nChecking container health...\n\nContainer Logs:\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2022-08-12T10:00:33,099992013+00:00 - iot-server/run \n2022-08-12T10:00:33,100423620+00:00 - rsyslog/run \n2022-08-12T10:00:33,102158445+00:00 - gunicorn/run \n2022-08-12T10:00:33,103741669+00:00 - nginx/run \n2022-08-12T10:00:33,107633627+00:00 | gunicorn/run | \n2022-08-12T10:00:33,110140764+00:00 | gunicorn/run | ###############################################\n2022-08-12T10:00:33,113188909+00:00 | gunicorn/run | AzureML Container Runtime Information\n2022-08-12T10:00:33,116821263+00:00 | gunicorn/run | ###############################################\n2022-08-12T10:00:33,119220299+00:00 | gunicorn/run | \n2022-08-12T10:00:33,121603034+00:00 | gunicorn/run | \n2022-08-12T10:00:33,123923369+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2022-08-12T10:00:33,126288804+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2022-08-12T10:00:33,128600938+00:00 | gunicorn/run | \n2022-08-12T10:00:33,131561182+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nbash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by bash)\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2022-08-12T10:00:38,934147869+00:00 - iot-server/finish 1 0\n2022-08-12T10:00:38,936812010+00:00 - Exit code 1 is normal. Not restarting iot-server.\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nadal==1.2.7\nargcomplete==2.0.0\nattrs==22.1.0\nazure-common==1.1.28\nazure-core==1.25.0\nazure-graphrbac==0.61.1\nazure-identity==1.7.0\nazure-mgmt-authorization==2.0.0\nazure-mgmt-containerregistry==10.0.0\nazure-mgmt-core==1.3.1\nazure-mgmt-keyvault==10.1.0\nazure-mgmt-resource==21.1.0\nazure-mgmt-storage==20.0.0\nazureml-core==1.44.0\nazureml-dataprep==4.2.2\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.8.1\nazureml-dataset-runtime==1.44.0\nazureml-defaults==1.44.0\nazureml-inference-server-http==0.7.4\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==3.2.2\ncachetools==5.2.0\ncertifi @ file:///opt/conda/conda-bld/certifi_1655968806487/work/certifi\ncffi==1.15.1\ncharset-normalizer==2.1.0\nclick==8.1.3\ncloudpickle==2.1.0\nconfigparser==3.7.4\ncontextlib2==21.6.0\ncryptography==37.0.4\ndistro==1.7.0\ndocker==5.0.3\ndotnetcore2==3.1.23\nFlask==2.1.3\nFlask-Cors==3.0.10\nfusepy==3.0.1\ngoogle-api-core==2.8.2\ngoogle-auth==2.10.0\ngoogleapis-common-protos==1.56.4\ngunicorn==20.1.0\nhumanfriendly==10.0\nidna==3.3\nimportlib-metadata==4.12.0\nimportlib-resources==5.9.0\ninference-schema==1.4.1\nisodate==0.6.1\nitsdangerous==2.1.2\njeepney==0.8.0\nJinja2==3.1.2\njmespath==1.0.0\njoblib @ file:///tmp/build/80754af9/joblib_1635411271373/work\njson-logging-py==0.2\njsonpickle==2.2.0\njsonschema==4.9.1\nknack==0.9.0\nMarkupSafe==2.1.1\nmkl-fft==1.3.1\nmkl-random @ file:///tmp/build/80754af9/mkl_random_1626186064646/work\nmkl-service==2.4.0\nmsal==1.18.0\nmsal-extensions==0.3.1\nmsrest==0.7.1\nmsrestazure==0.6.4\nndg-httpsclient==0.5.1\nnumpy @ file:///opt/conda/conda-bld/numpy_and_numpy_base_1652801679809/work\noauthlib==3.2.0\nopencensus==0.11.0\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.6\npackaging==21.3\nparamiko==2.11.0\npathspec==0.9.0\npkginfo==1.8.3\npkgutil_resolve_name==1.3.10\nportalocker==2.5.1\nprotobuf==4.21.5\npsutil==5.9.1\npyarrow==6.0.0\npyasn1==0.4.8\npyasn1-modules==0.2.8\npycparser==2.21\nPygments==2.12.0\nPyJWT==2.4.0\nPyNaCl==1.5.0\npyOpenSSL==22.0.0\npyparsing==3.0.9\npyrsistent==0.18.1\nPySocks==1.7.1\npython-dateutil==2.8.2\npytz==2022.1\nPyYAML==6.0\nrequests==2.28.1\nrequests-oauthlib==1.3.1\nrsa==4.9\nscikit-learn @ file:///tmp/build/80754af9/scikit-learn_1642617107864/work\nscipy @ file:///tmp/build/80754af9/scipy_1641555001653/work\nSecretStorage==3.3.2\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\ntabulate==0.8.10\nthreadpoolctl @ file:///Users/ktietz/demo/mc3/conda-bld/threadpoolctl_1629802263681/work\ntyping_extensions==4.3.0\nurllib3==1.26.9\nwebsocket-client==1.3.3\nWerkzeug==2.2.2\nwrapt==1.12.1\nzipp==3.8.1\n\n2022-08-12T10:00:42,366904140+00:00 | gunicorn/run | \n2022-08-12T10:00:42,368995472+00:00 | gunicorn/run | ###############################################\n2022-08-12T10:00:42,370970503+00:00 | gunicorn/run | AzureML Inference Server\n2022-08-12T10:00:42,372911433+00:00 | gunicorn/run | ###############################################\n2022-08-12T10:00:42,374820863+00:00 | gunicorn/run | \n2022-08-12T10:00:42,376906795+00:00 | gunicorn/run | \n2022-08-12T10:00:42,378822525+00:00 | gunicorn/run | Starting HTTP server\n2022-08-12T10:00:42,380885657+00:00 | gunicorn/run | \nStarting gunicorn 20.1.0\nListening at: http://127.0.0.1:31311 (13)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 58\nSPARK_HOME not set. Skipping PySpark Initialization.\nInitializing logger\n2022-08-12 10:01:14,617 | root | INFO | Starting up app insights client\nlogging socket was found. logging is available.\nlogging socket was found. logging is available.\n2022-08-12 10:01:14,617 | root | INFO | Starting up request id generator\n2022-08-12 10:01:14,618 | root | INFO | Starting up app insight hooks\n2022-08-12 10:01:14,618 | root | INFO | Invoking user's init function\n00000000-0000-0000-0000-000000000000,None\n2022-08-12 10:01:14,618 | root | ERROR | User's init function failed\n2022-08-12 10:01:14,638 | root | ERROR | Encountered Exception Traceback (most recent call last):\n  File \"/var/azureml-server/aml_blueprint.py\", line 217, in register\n    main.init()\n  File \"/var/azureml-app/score.py\", line 16, in init\n    print(Model.get_model_path(model_name='model_alpha_0.1.pkl'))\n  File \"/azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/python3.8/site-packages/azureml/core/model.py\", line 807, in get_model_path\n    return Model._get_model_path_local(model_name, version)\n  File \"/azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/python3.8/site-packages/azureml/core/model.py\", line 828, in _get_model_path_local\n    return Model._get_model_path_local_from_root(model_name)\n  File \"/azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/python3.8/site-packages/azureml/core/model.py\", line 870, in _get_model_path_local_from_root\n    raise ModelNotFoundException(\"Model {} not found in cache at {} or in current working directory {}. \"\nazureml.exceptions._azureml_exception.ModelNotFoundException: ModelNotFoundException:\n\tMessage: Model model_alpha_0.1.pkl not found in cache at azureml-models or in current working directory /var/azureml-app. For more info, set logging level to DEBUG.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Model model_alpha_0.1.pkl not found in cache at azureml-models or in current working directory /var/azureml-app. For more info, set logging level to DEBUG.\"\n    }\n}\n\n2022-08-12 10:01:14,638 | root | INFO | Waiting for logs to be sent to Application Insights before exit.\n2022-08-12 10:01:14,638 | root | INFO | Waiting 30 seconds for upload.\nWorker exiting (pid: 58)\nShutting down: Master\nReason: Worker failed to boot.\n/bin/bash: /azureml-envs/azureml_cdac53350582a78a48f29cd457ee19c9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2022-08-12T10:01:45,499300423+00:00 - gunicorn/finish 3 0\n2022-08-12T10:01:45,501587458+00:00 - Exit code 3 is not normal. Killing image.\n\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Error: Container has crashed. Did your init method fail?\n\n"
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m deployment_config \u001b[38;5;241m=\u001b[39m LocalWebservice\u001b[38;5;241m.\u001b[39mdeploy_configuration(port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6789\u001b[39m)\n\u001b[1;32m      6\u001b[0m local_service \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mdeploy(ws, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, [model], inference_config, deployment_config)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mlocal_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_deployment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(local_service\u001b[38;5;241m.\u001b[39mstate)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/local.py:72\u001b[0m, in \u001b[0;36m_in_state.<locals>.decorator.<locals>.decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m states:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WebserviceException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot call \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m() when service is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate),\n\u001b[1;32m     71\u001b[0m                               logger\u001b[38;5;241m=\u001b[39mmodule_logger)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/local.py:611\u001b[0m, in \u001b[0;36mLocalWebservice.wait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03mPoll the running LocalWebservice deployment.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03m:raises: :class:`azureml.exceptions.WebserviceException`\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m     \u001b[43mcontainer_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_container\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mhealth_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_health_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcleanup_if_failed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m LocalWebservice\u001b[38;5;241m.\u001b[39mSTATE_RUNNING\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocal webservice is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_url))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_model_management/_util.py:750\u001b[0m, in \u001b[0;36mcontainer_health_check\u001b[0;34m(docker_port, container, health_url, cleanup_if_failed)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m container\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexited\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;66;03m# The container has started and crashed.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m     \u001b[43m_raise_for_container_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcleanup_if_failed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mError: Container has crashed. Did your init method fail?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# The container hasn't crashed, so try to ping the health endpoint.\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_model_management/_util.py:1267\u001b[0m, in \u001b[0;36m_raise_for_container_failure\u001b[0;34m(container, cleanup, message)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m   1265\u001b[0m     cleanup_container(container)\n\u001b[0;32m-> 1267\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m WebserviceException(message, logger\u001b[38;5;241m=\u001b[39mmodule_logger)\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1660298508064
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}